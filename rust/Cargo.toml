[package]
name = "rust"
version = "0.1.0"
edition = "2024"

[dependencies]
axum = "0.8.8"
tokio = { version = "1.0", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
anyhow = "1.0"
serde_json = "1.0"
futures = "0.3"
tokio-stream = "0.1"

# Note: "cuda" feature forces strict linking. 
# Ensure CUDA drivers are present on the target machine, 
# even if you intend to fallback to CPU.
# you can use only CPU version by using below
llama-cpp-2 = { version = "0.1.130",default-features = false,  features = [ "sampler"] }
# GPU
# llama-cpp-2 = { version = "0.1.130", features = ["cuda", "sampler"] }
rand = "0.8" # Added this (Required for LlamaSampler::dist)

# Tracing/Logging (Essential for Prod)
tracing = "0.1"
tracing-subscriber = "0.3"

[features]
# e.g., cargo build --no-default-features --features vulkan
# default = ["cuda"]
vulkan = ["llama-cpp-2/vulkan"]
cuda = ["llama-cpp-2/cuda"]
metal = ["llama-cpp-2/metal"]